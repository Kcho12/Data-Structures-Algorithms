{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heaps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "For this assignment you will start by modifying the heap data stucture implemented in class to allow it to keep its elements sorted by an arbitrary priority (identified by a `key` function), then use the augmented heap to efficiently compute the running median of a set of numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Augmenting the Heap with a `key` function\n",
    "\n",
    "The heap implementation covered in class is for a so-called \"max-heap\" — i.e., one where elements are organized such that the one with the maximum value can be efficiently extracted.\n",
    "\n",
    "This limits our usage of the data structure, however. Our heap can currently only accommodate elements that have a natural ordering (i.e., they can be compared using the '`>`' and '`<`' operators as used in the implementation), and there's no way to order elements based on some partial or computed property.\n",
    "\n",
    "To make our heap more flexible, you'll update it to allow a `key` function to be passed to its initializer. This function will be used to extract a value from each element added to the heap; these values, in turn, will be used to order the elements. \n",
    "\n",
    "We can now easily create heaps with different semantics, e.g.,\n",
    "\n",
    "- `Heap(len)` will prioritize elements based on their length (e.g., applicable to strings, sequences, etc.)\n",
    "- `Heap(lambda x: -x)` can function as a *min-heap* for numbers\n",
    "- `Heap(lambda x: x.prop)` will prioritize elements based on their `prop` attribute\n",
    "\n",
    "If no `key` function is provided, the default max-heap behavior should be used — the \"`lambda x:x`\" default value for the `__init__` method does just that. \n",
    "\n",
    "You will, at the very least, need to update the `_heapify` and `add` methods, below, to complete this assignment. (Note, also, that `pop_max` has been renamed `pop`, while `max` has been renamed `peek`, to reflect their more general nature.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "heap",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "class Heap:\n",
    "    def __init__(self, key=lambda x:x):\n",
    "        self.data = []\n",
    "        self.key  = key\n",
    "\n",
    "    @staticmethod\n",
    "    def _parent(idx):\n",
    "        return (idx-1)//2\n",
    "        \n",
    "    @staticmethod\n",
    "    def _left(idx):\n",
    "        return idx*2+1\n",
    "\n",
    "    @staticmethod\n",
    "    def _right(idx):\n",
    "        return idx*2+2\n",
    "    \n",
    "    def heapify(self, idx=0):#Edit this code for specific keys\n",
    "        idx = 0\n",
    "        max_idx = idx  \n",
    "        \n",
    "        while idx < len(self.data):\n",
    "            lidx = Heap._left(idx)\n",
    "            ridx = Heap._right(idx)\n",
    "\n",
    "            #compare left child with current node\n",
    "            if lidx <len(self.data) and self.key(self.data[lidx]) > self.key(self.data[idx]):\n",
    "                max_idx = lidx\n",
    "\n",
    "            #compare right child wth max(parent, left child)\n",
    "            if ridx <len(self.data) and self.key(self.data[ridx]) > self.key(self.data[max_idx]):\n",
    "                max_idx = ridx\n",
    "\n",
    "            if max_idx != idx: # the max is not in the parent\n",
    "                self.data[max_idx], self.data[idx] = self.data[idx], self.data[max_idx]\n",
    "                idx = max_idx\n",
    "\n",
    "            else: # the right position is located already\n",
    "                break\n",
    "            \n",
    "    def add(self, x):#Edit this for specific keys\n",
    "        self.data.append(x) #initially add new element to the end\n",
    "        idx = len(self.data) -1 #get index of newly added node\n",
    "        pidx = Heap._parent(idx) # get the index of its parent node\n",
    "        \n",
    "        while idx > 0 and self.key(self.data[pidx]) < self.key(self.data[idx]): #compares child node to parent node of the tree\n",
    "            self.data[pidx], self.data[idx] = self.data[idx], self.data[pidx] # swap if child node is longer than parent\n",
    "            idx = pidx\n",
    "            pidx = Heap._parent(idx)\n",
    "        \n",
    "    def peek(self):\n",
    "        return self.data[0]\n",
    "\n",
    "    def pop(self):\n",
    "        ret = self.data[0]\n",
    "        self.data[0] = self.data[len(self.data)-1]\n",
    "        del self.data[len(self.data)-1]\n",
    "        self.heapify()\n",
    "        return ret\n",
    "    \n",
    "    def __bool__(self):\n",
    "        return len(self.data) > 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return repr(self.data)\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "heap_test_1",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 point)\n",
    "\n",
    "from unittest import TestCase\n",
    "import random\n",
    "\n",
    "tc = TestCase()\n",
    "h = Heap()\n",
    "\n",
    "random.seed(0)\n",
    "for _ in range(10):\n",
    "    h.add(random.randrange(100))\n",
    "\n",
    "tc.assertEqual(h.data, [97, 61, 65, 49, 51, 53, 62, 5, 38, 33])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "heap_test_2",
     "locked": true,
     "points": 1,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (1 point)\n",
    "\n",
    "from unittest import TestCase\n",
    "import random\n",
    "\n",
    "tc = TestCase()\n",
    "h = Heap(lambda x:-x)\n",
    "\n",
    "random.seed(0)\n",
    "for _ in range(10):\n",
    "    h.add(random.randrange(100))\n",
    "\n",
    "tc.assertEqual(h.data, [5, 33, 53, 38, 49, 65, 62, 97, 51, 61])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "heap_test_3",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 points)\n",
    "\n",
    "from unittest import TestCase\n",
    "import random\n",
    "\n",
    "tc = TestCase()\n",
    "h = Heap(lambda s:len(s))\n",
    "\n",
    "h.add('hello')\n",
    "h.add('hi')\n",
    "h.add('abracadabra')\n",
    "h.add('supercalifragilisticexpialidocious')\n",
    "h.add('0')\n",
    "\n",
    "tc.assertEqual(h.data,\n",
    "              ['supercalifragilisticexpialidocious', 'abracadabra', 'hello', 'hi', '0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "heap_test_4",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 points)\n",
    "\n",
    "from unittest import TestCase\n",
    "import random\n",
    "\n",
    "tc = TestCase()\n",
    "h = Heap()\n",
    "\n",
    "random.seed(0)\n",
    "lst = list(range(-1000, 1000))\n",
    "random.shuffle(lst)\n",
    "\n",
    "for x in lst:\n",
    "    h.add(x)\n",
    "\n",
    "for x in range(999, -1000, -1):\n",
    "    tc.assertEqual(x, h.pop())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "heap_test_5",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 points)\n",
    "\n",
    "from unittest import TestCase\n",
    "import random\n",
    "\n",
    "tc = TestCase()\n",
    "h = Heap(key=lambda x:abs(x))\n",
    "\n",
    "random.seed(0)\n",
    "lst = list(range(-1000, 1000, 3))\n",
    "random.shuffle(lst)\n",
    "\n",
    "for x in lst:\n",
    "    h.add(x)\n",
    "\n",
    "for x in reversed(sorted(range(-1000, 1000, 3), key=lambda x:abs(x))):\n",
    "    tc.assertEqual(x, h.pop())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Computing the Running Median\n",
    "\n",
    "The median of a series of numbers is simply the middle term if ordered by magnitude, or, if there is no middle term, the average of the two middle terms. E.g., the median of the series [3, 1, 9, 25, 12] is **9**, and the median of the series [8, 4, 11, 18] is **9.5**.\n",
    "\n",
    "If we are in the process of accumulating numerical data, it is useful to be able to compute the *running median* — where, as each new data point is encountered, an updated median is computed. This should be done, of course, as efficiently as possible.\n",
    "\n",
    "The following function demonstrates a naive way of computing the running medians based on the series passed in as an iterable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def running_medians_naive(iterable):\n",
    "    values = []\n",
    "    medians = []\n",
    "    for i, x in enumerate(iterable):\n",
    "        values.append(x)\n",
    "        values.sort()\n",
    "        if i%2 == 0:\n",
    "            medians.append(values[i//2])\n",
    "        else:\n",
    "            medians.append((values[i//2] + values[i//2+1]) / 2)\n",
    "    return medians\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2.0, 3, 6.0, 9]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_medians_naive([3, 1, 9, 25, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 6.0, 8, 9.5]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_medians_naive([8, 4, 11, 18])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the function keeps track of all the values encountered during the iteration and uses them to compute the running medians, which are returned at the end as a list. The final running median, naturally, is simply the median of the entire series.\n",
    "\n",
    "Unfortunately, because the function sorts the list of values during every iteration it is incredibly inefficient. Your job is to implement a version that computes each running median in O(log N) time using, of course, the heap data structure!\n",
    "\n",
    "### Hints\n",
    "\n",
    "- You will need to use two heaps for your solution: one min-heap, and one max-heap. \n",
    "- The min-heap should be used to keep track of all values *greater than* the most recent running median, and the max-heap for all values *less than* the most recent running median — this way, the median will lie between the minimum value on the min-heap and the maximum value on the max-heap (both of which can be efficiently extracted)\n",
    "- In addition, the difference between the number of values stored in the min-heap and max-heap must never exceed 1 (to ensure the median is being computed). This can be taken care of by intelligently `pop`-ping/`add`-ing elements between the two heaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "running_median",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "#<GRADED>\n",
    "def running_medians(iterable):\n",
    "    h = Heap(lambda x: -x)\n",
    "    hmax = Heap()\n",
    "    medians = []\n",
    "    for i, x in enumerate(iterable):\n",
    "        if not h.data:\n",
    "            h.add(x)\n",
    "            medians.append(h.data[0])\n",
    "        elif x < h.data[0]: # if item in minheap is bigger than next item send it to maxheap\n",
    "            hmax.add(x)\n",
    "            if len(hmax.data) == len(h.data) + 2:\n",
    "                h.add(hmax.data[0])\n",
    "                hmax.pop()\n",
    "            elif len(hmax.data) > len(h.data):#if min heap is bigger than maxheap add to median\n",
    "                medians.append(hmax.data[0])\n",
    "        else:\n",
    "            h.add(x)\n",
    "            if len(h.data) == len(hmax.data) + 2:\n",
    "                hmax.add(h.data[0])\n",
    "                h.pop()\n",
    "            elif len(h.data) > len(hmax.data): #If max heap is bigger than minheap add to median\n",
    "                medians.append(h.data[0])\n",
    "            \n",
    "        if len(h.data) == len(hmax.data): #If heaps have same len(elements) then return the average of those two\n",
    "            medians.append((h.data[0]+ hmax.data[0])/2)\n",
    "    \n",
    "    return medians\n",
    "#</GRADED>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "running_median_1",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 points)\n",
    "\n",
    "from unittest import TestCase\n",
    "tc = TestCase()\n",
    "tc.assertEqual([3, 2.0, 3, 6.0, 9], running_medians([3, 1, 9, 25, 12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "running_median_2",
     "locked": true,
     "points": 2,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (2 points)\n",
    "\n",
    "import random\n",
    "from unittest import TestCase\n",
    "tc = TestCase()\n",
    "vals = [random.randrange(10000) for _ in range(1000)]\n",
    "tc.assertEqual(running_medians_naive(vals), running_medians(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "running_median_3",
     "locked": true,
     "points": 4,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# (4 points) MUST COMPLETE IN UNDER 10 seconds!\n",
    "\n",
    "import random\n",
    "from unittest import TestCase\n",
    "tc = TestCase()\n",
    "vals = [random.randrange(100000) for _ in range(100001)]\n",
    "m_mid   = sorted(vals[:50001])[50001//2]\n",
    "m_final = sorted(vals)[len(vals)//2]\n",
    "running = running_medians(vals)\n",
    "tc.assertEqual(m_mid, running[50000])\n",
    "tc.assertEqual(m_final, running[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
